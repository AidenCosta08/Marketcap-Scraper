# -*- coding: utf-8 -*-
"""Marketcap.ipynb
Automatically generated by Colab.
Original file is located at
    https://colab.research.google.com/drive/1R0c9wXYBcurfGR1BshB_7aCGkLNu-5P4
"""
import requests
from bs4 import BeautifulSoup
import pandas as pd

def get_website_info(link):
    try:
        webpage = requests.get(f'https://companiesmarketcap.com'+link)
        webpage.raise_for_status()  # Raises a HTTPError if the status is 4xx, 5xx
    except (requests.exceptions.RequestException, ValueError):
        return "An error occurred while trying to fetch data. for website info"

    soup = BeautifulSoup(webpage.content, "html.parser")
    boxes = soup.find(class_='table-container').find_all(class_='row')

    results = []
    for box in boxes:
        company_name_div = box.find('div', class_='company-name')
        company_logo_img = box.find('img', class_='company-profile-logo')
        company_code_div = box.find('div', class_='company-code')
        line1_divs = box.find_all('div', class_='line1')
        category_badges = box.find_all('a', class_='badge badge-light category-badge')
        company_description_div = box.find('div', class_='col-lg-4 company-description')

        result = {}

        result['CompanyLogo'] = 'https://companiesmarketcap.com' + company_logo_img['src'] if company_logo_img else 'No logo'
        result['Company'] = company_name_div.text.strip() if company_name_div else 'No company name'
        result['Code'] = company_code_div.text.strip() if company_code_div else 'No company code'
        result['Rank'] = line1_divs[0].text.strip() if line1_divs and len(line1_divs) > 0 else 'No rank'
        result['MarketCap'] = line1_divs[1].text.strip() if line1_divs and len(line1_divs) > 1 else 'No market cap'
        result['Country'] = line1_divs[2].text.strip() if line1_divs and len(line1_divs) > 2 else 'No country'
        result['Categories'] = ', '.join([category.text.strip().split(' ', 1)[-1] for category in category_badges]) if category_badges else 'No categories'
        result['Description'] = company_description_div.text.strip() if company_description_div else 'No description'

        results.append(result)

    return results[0] if results else None
    #return results


def get_page_names(link):
  try:
      webpage = requests.get(link)
      webpage.raise_for_status()  # Raises a HTTPError if the status is 4xx, 5xx
  except (requests.exceptions.RequestException, ValueError):
      return "An error occurred while trying to fetch data for page names."
  soup = BeautifulSoup(webpage.content, "html.parser")
  divs = soup.find_all('div', class_='name-div')
  links = [a['href'] for div in divs for a in div.find_all('a', href=True)]
  return links


def website_page_list():
  try:
    webpage = requests.get(f'https://companiesmarketcap.com/page/1/')
    webpage.raise_for_status()  # Raises a HTTPError if the status is 4xx, 5xx
  except (requests.exceptions.RequestException, ValueError):
    return "An error occurred while trying to fetch data for page names."
  soup = BeautifulSoup(webpage.content, "html.parser")
  divs = soup.find('span', class_='companies-count')
  page_amount = int(divs.text.replace(',', '')) // 100 + 1
  final_page_list = []
  for i in range(1, page_amount + 1):
    final_page_list.append(f'https://companiesmarketcap.com/page/{i+83}/')
  return final_page_list 



website_link_list = []
num=84
for x in website_page_list():
    for link in get_page_names(x): 
        website_link_list.append(get_website_info(link))
        df = pd.DataFrame(website_link_list)
        df.to_csv('marketcap'+ str(num) +'.csv')
    website_link_list = []
    num+=1
print(website_link_list)

